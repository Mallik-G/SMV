<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link rel="stylesheet" type="text/css" href="github.css">
</head>
<body>
<table class="nav-table">
    <tr>
        <td class="nav-left">&lArr;&nbsp;<a href="smv_module.html">SMV Scala Modules</a></td>
        <td class="nav-center"><a href="0_user_toc.html">Table Of Contents</a></td>
        <td class="nav-right"><a href="smv_hive.html">SMV Hive Tables</a>&nbsp;&rArr;</td>
    </tr>
</table>
<hr>

<article class="markdown-body">
<h1 id="smv-python-modules">SMV Python Modules</h1>
<h2 id="smvpydataset">SmvPyDataSet</h2>
<p>The Python base class <code>SmvPyDataSet</code> implements shared functionalities such as <code>modulePath()</code>, <code>fqn()</code>, <code>isInput()</code> etc. It also ensures that all subclass must implement the following abstract methods:</p>
<ul>
<li>Class docstring - what is this dataset about</li>
<li><code>requiresDS</code> - the upstream dependencies, in other words, what other datasets need to be run first</li>
<li><code>run(i)</code> - how to compute this dataset from the input declared in <code>requiresDS</code></li>
</ul>
<p><strong>Note:</strong> <code>SmvPyDataSet</code> is a base class, user should not use it directly.</p>
<h2 id="smvpycsvfile">SmvPyCsvFile</h2>
<p>The simplest type of input dataset. To create a Python module representing input from a csv file, subclass <code>SmvPyCsvFile</code> as show below</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> smv <span class="im">import</span> <span class="op">*</span>
<span class="kw">class</span> PythonCsvFile(SmvPyCsvFile):
    <span class="kw">def</span> path(<span class="va">self</span>):
        <span class="cf">return</span> <span class="st">&quot;path/to/filename.csv&quot;</span>

    <span class="kw">def</span> csvAttr(<span class="va">self</span>):
        <span class="cf">return</span> <span class="va">self</span>.defaultCsvWithHeader()</code></pre></div>
<p>The <code>path</code> method (annotated as a property) is equivalent to the constructor parameter <code>path</code> in Scala; it returns the path to the input file. All subclasses must provide an implementation for this method. The <code>csvAttr()</code> method is optional. The default implementation returns <code>None</code>, which maps to <code>null</code> in Java. The meaning of having no <code>csvAttr()</code> is such that SMV runtime will read the schema information stored in the corresponding <code>.schema</code> file. Alternatively, the subclass can also provide a csvAttr. There are 3 factory methods in <code>SmvPyCsvFile</code>: <code>defaultCsvWithHeader</code>, <code>defaultTsv</code> (tab-delimited format), and <code>defaultTsvWithHeader</code>. These correspond to their Scala counterparts.</p>
<h2 id="smvpyhivetable">SmvPyHiveTable</h2>
<p>Smv input dataset from a Hive table.</p>
<p>E.g.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">class</span> Phyn(SmvPyHiveTable):
    <span class="co">&quot;&quot;&quot;Physician table&quot;&quot;&quot;</span>
    <span class="kw">def</span> tableName(<span class="va">self</span>):
        <span class="cf">return</span> <span class="st">&quot;hive_schema1.phyn_dim&quot;</span></code></pre></div>
<p>Please note that to be able to access Hive tables from SMV, you need to have Spark configured to be able to access Hive.<br />
Also the user of SMV have to have access to the specified Hive schema (in the example, <code>hive_schema1</code>).</p>
<h2 id="smvpycsvstringdata">SmvPyCsvStringData</h2>
<p>Smv input dataset from a string.</p>
<p>Sometimes we simply need to create some small reference tables as <code>SmvPyDataSet</code>. Instead of have the manually create the<br />
Csv file of Hive tables and then imported through <code>SmvPyCsvFile</code> or <code>SmvHiveTable</code>, we can just code the data string<br />
in a <code>SmvPyCsvStringData</code>.</p>
<p>E.g.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">class</span> RefT1(SmvPyCsvStringData):
    <span class="co">&quot;&quot;&quot;From Ref1.xlsx&quot;&quot;&quot;</span>
    <span class="kw">def</span> schemaStr(<span class="va">self</span>): <span class="cf">return</span> <span class="st">&quot;ID:String;Name:String&quot;</span>
    <span class="kw">def</span> dataStr(<span class="va">self</span>):
        <span class="cf">return</span> <span class="st">&quot;&quot;&quot;0000276690114,ABC;</span>
<span class="st">            0000276780114,BCD&quot;&quot;&quot;</span></code></pre></div>
<h2 id="smvpymodule">SmvPyModule</h2>
<p>To create an SMV module in Python, subclass <code>SmvPyModule</code> and override the 2 abstract methods listed in the section on SmvPyDataSet.</p>
<p>The <code>requiresDS</code> method returns the dependencies in an array (of Classes).</p>
<p>The parameter <code>i</code> that's passed to the <code>run</code> method is named the same way as in the Scala API. The <code>i</code> is a dictionary mapping module class to its resulting <code>DataFrame</code>s. Through it modules can retrieve the results of its dependent modules.</p>
<p>Within the <code>run</code> methods, all operations on Spark DataFrames are available, as well as most of SMV enrichments to the Spark SQL API.</p>
<p>E.g.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">class</span> PythonEmploymentByState(SmvPyModule):
    <span class="co">&quot;&quot;&quot;Python ETL Example: employ by state&quot;&quot;&quot;</span>

    <span class="kw">def</span> requiresDS(<span class="va">self</span>):
        <span class="cf">return</span> [inputdata.PythonEmployment]

    <span class="kw">def</span> run(<span class="va">self</span>, i):
        df <span class="op">=</span> i[inputdata.PythonEmployment]
        <span class="cf">return</span> df.groupBy(col(<span class="st">&quot;ST&quot;</span>)).agg(<span class="bu">sum</span>(col(<span class="st">&quot;EMP&quot;</span>)).alias(<span class="st">&quot;EMP&quot;</span>))</code></pre></div>
<h1 id="smvpyoutput">SmvPyOutput</h1>
<p><code>SmvPyOutput</code> is not a stand-along <code>SmvPyDataSet</code>. It can be mixed in with other <code>SmvDataSet</code> to label them as an<br />
output module.</p>
<p>To support export a module to a Hive table, <code>SmvPyOutput</code> provides a method <code>tableName</code>, where user code can provide<br />
a Hive table name, so that when run time command specified to export this module, Smv will export data to Hive.</p>
<p>E.g.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">class</span> KPI(SmvPyModule, SmvPyOutput):
    <span class="co">&quot;&quot;&quot;</span>
<span class="co">    Normalized KPI</span>
<span class="co">    &quot;&quot;&quot;</span>
    <span class="kw">def</span> tableName(<span class="va">self</span>): <span class="cf">return</span> <span class="st">&#39;hive_bi_schema.nrmlz_kpi&#39;</span>

    <span class="kw">def</span> requiresDS(<span class="va">self</span>):
        <span class="cf">return</span> [...]

    <span class="kw">def</span> run(<span class="va">self</span>, i):
        ...</code></pre></div>
<p>To save a module to a Hive table, use the <code>smv-pyrun</code> command, passing <code>--publish-hive</code> option. With this<br />
operation, the runner will look for <code>SmvPyOutput</code> with <code>tableName</code> from all the specified modules (commandline<br />
 with the <code>-m</code> switch), after resolving them, it will push them to specified Hive tables.</p>
<p>E.g. of a launching script</p>
<pre class="sh"><code>smv-pyrun --data-dir &quot;${DATA_DIR}&quot; --publish-hive -m \
  com.myapp.KPI \
  -- \
  --master yarn-client \
  --executor-memory ${EXECUTOR_MEMORY} \
  --driver-memory ${DRIVER_MEMORY} \
  --conf spark.dynamicAllocation.maxExecutors=${MAX_EXECUTORS} \
  --conf spark.yarn.queue=${YARN_QUEUE} \
  --conf spark.executor.cores=${EXECUTOR_CORES} \
  --conf spark.yarn.executor.memoryOverhead=${MEMORY_OVERHEAD} \
  2&gt;&amp;1 | tee $LOGFILE</code></pre>
</article>
</body>
</html>
